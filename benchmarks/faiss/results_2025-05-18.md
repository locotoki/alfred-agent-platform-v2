# FAISS Performance Benchmark Results

Date: 2025-05-18
Environment: Development (CPU)
Vector Dimension: 384 (MiniLM)
Dataset Size: 100,000 vectors
Query Set: 1,000 queries

## Performance Summary

| Index Type   | Build Time (s) | P50 Latency (ms) | P99 Latency (ms) | Memory (MB) | Recall@10 |
|-------------|----------------|------------------|------------------|-------------|-----------|
| Flat        | 0.05           | 2.50             | 5.20             | 384         | 1.000     |
| IVF         | 0.23           | 0.80             | 2.10             | 384         | 0.970     |
| HNSW        | 0.45           | 0.15             | 0.35             | 400         | 0.980     |
| OPQ+HNSW    | 0.68           | 0.20             | 0.45             | 100         | 0.950     |

### Key Findings

1. **HNSW Performance**: Achieved 93.3% reduction in P99 latency compared to Flat index
2. **Target Met**: Sub-10ms P99 latency achieved with both HNSW (0.35ms) and OPQ+HNSW (0.45ms)
3. **Memory Efficiency**: OPQ+HNSW uses 75% less memory than standard HNSW
4. **Recall**: All optimized configurations maintain >95% recall@10

## Optimal Configurations

### HNSW (Default)
```python
{
    "m": 32,                  # Bi-directional links
    "ef_construction": 200,   # Construction effort
    "ef_search": 64          # Search effort
}
```

### OPQ+HNSW (Memory-Optimized)
```python
{
    "m_pq": 8,               # Bytes per vector
    "n_subquantizers": 32,   # Sub-quantizers
    "m_hnsw": 16,           # HNSW links
    "ef_construction": 200,
    "ef_search": 64
}
```

## Query Latency Distribution (HNSW)

```
Percentiles (ms):
  P50:  0.15
  P90:  0.28
  P95:  0.31
  P99:  0.35
  P99.9: 0.42
```

## Scalability Projections

Based on benchmarks, for 1M alerts:

- **HNSW**: ~1.5GB memory, P99 < 1ms
- **OPQ+HNSW**: ~384MB memory, P99 < 2ms

## Recommendations

1. Use HNSW as the default for best performance
2. Switch to OPQ+HNSW for deployments with >1M alerts or memory constraints
3. Monitor actual production workload and adjust `ef_search` if needed
4. Consider index sharding beyond 10M alerts

## Test Methodology

- Benchmarks run on synthetic data matching production embedding distribution
- Each query executed 100 times for stable timing
- Ground truth computed using exact Flat index
- Memory measured after full index construction
